#!/usr/bin/env python3
"""Archive legacy single-product listings that duplicate consolidated variants.

This script reads ``outputs/variant_consolidation/potential_variant_groups.csv``
(which is generated by the audit tooling) and identifies handles marked with the
``archive`` category. Handles that already exist in the consolidated variant CSV
are skipped so that only the old single-product listings are touched.

Each matching product is set to ``draft`` status via the Admin REST API. Use the
``--dry-run`` flag to preview the actions without modifying Shopify.
"""

from __future__ import annotations

import argparse
import csv
import os
import sys
import time
from pathlib import Path
from typing import Dict, Iterable, List, Set

import requests

DEFAULT_REPORT_PATH = Path("outputs/variant_consolidation/potential_variant_groups.csv")
CONSOLIDATED_CSV = Path("outputs/variant_consolidation/variant_consolidation.csv")
SHOPIFY_API_VERSION = os.environ.get("SHOPIFY_API_VERSION", "2023-10")
DEFAULT_THROTTLE = 0.4


def load_consolidated_handles(path: Path) -> Set[str]:
    handles: Set[str] = set()
    if not path.exists():
        return handles
    with path.open(encoding="utf-8") as handle:
        reader = csv.DictReader(handle)
        for row in reader:
            handle_value = (row.get("Handle") or "").strip()
            if handle_value:
                handles.add(handle_value)
    return handles


def harvest_archive_handles(report_path: Path, consolidated_handles: Set[str]) -> List[str]:
    if not report_path.exists():
        raise FileNotFoundError(f"Grouping report not found: {report_path}")

    to_archive: List[str] = []
    seen: Set[str] = set()

    with report_path.open(encoding="utf-8") as handle:
        reader = csv.DictReader(handle)
        for row in reader:
            if (row.get("category") or "").strip().lower() != "archive":
                continue
            for handle_value in (row.get("handles") or "").split("|"):
                slug = handle_value.strip()
                if not slug or slug in consolidated_handles or slug in seen:
                    continue
                seen.add(slug)
                to_archive.append(slug)

    return to_archive


def product_id_by_handle(session: requests.Session, graphql_url: str, handle: str) -> str | None:
    query = """
    query($handle: String!) {
      productByHandle(handle: $handle) {
        id
        status
      }
    }
    """
    response = session.post(graphql_url, json={"query": query, "variables": {"handle": handle}}, timeout=30)
    response.raise_for_status()
    data: Dict[str, Dict[str, Dict[str, str]]] = response.json()
    product = data.get("data", {}).get("productByHandle")
    if not product:
        return None
    gid = product.get("id")
    return gid.split("/")[-1] if gid else None


def archive_product(session: requests.Session, rest_base: str, product_id: str, throttle: float) -> None:
    payload = {"product": {"id": int(product_id), "status": "draft"}}
    url = f"{rest_base}/products/{product_id}.json"
    response = session.put(url, json=payload, timeout=30)
    if response.status_code not in (200, 201):
        raise RuntimeError(f"Failed to archive product {product_id}: {response.status_code} {response.text}")
    time.sleep(throttle)


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Archive legacy Shopify products that duplicate consolidated variants")
    parser.add_argument("--report", type=Path, default=DEFAULT_REPORT_PATH, help="Path to potential_variant_groups.csv")
    parser.add_argument("--consolidated", type=Path, default=CONSOLIDATED_CSV, help="Path to consolidated variant CSV")
    parser.add_argument("--throttle", type=float, default=DEFAULT_THROTTLE, help="Delay between API calls in seconds")
    parser.add_argument("--limit", type=int, help="Process at most this many products")
    parser.add_argument("--dry-run", action="store_true", help="Preview affected products without API writes")
    return parser.parse_args()


def main() -> int:
    args = parse_args()

    access_token = os.environ.get("SHOPIFY_ACCESS_TOKEN")
    domain = os.environ.get("SHOPIFY_DOMAIN")

    missing = [name for name, value in (("SHOPIFY_ACCESS_TOKEN", access_token), ("SHOPIFY_DOMAIN", domain)) if not value]
    if missing:
        print(f"âŒ Missing required environment variables: {', '.join(missing)}", file=sys.stderr)
        return 1

    domain = domain.strip().lower()
    if not domain.endswith(".myshopify.com"):
        domain = f"{domain}.myshopify.com"

    consolidated_handles = load_consolidated_handles(args.consolidated)
    archive_handles = harvest_archive_handles(args.report, consolidated_handles)

    if not archive_handles:
        print("âœ… No legacy handles require archiving")
        return 0

    if args.limit is not None:
        archive_handles = archive_handles[: args.limit]

    rest_base = f"https://{domain}/admin/api/{SHOPIFY_API_VERSION}"
    graphql_url = f"https://{domain}/admin/api/{SHOPIFY_API_VERSION}/graphql.json"

    session = requests.Session()
    session.headers.update({
        "Content-Type": "application/json",
        "Accept": "application/json",
        "X-Shopify-Access-Token": access_token,
    })

    archived = 0
    skipped = 0
    missing_handles: List[str] = []

    for index, handle in enumerate(archive_handles, start=1):
        print(f"[{index}/{len(archive_handles)}] Archiving handle '{handle}'")
        try:
            product_id = product_id_by_handle(session, graphql_url, handle)
        except requests.HTTPError as exc:
            print(f"  âš ï¸  Failed to look up product: {exc}")
            skipped += 1
            continue

        if not product_id:
            print("  âš ï¸  No product found with that handle; skipping")
            missing_handles.append(handle)
            skipped += 1
            continue

        if args.dry_run:
            print(f"  ðŸ“ Dry run â€“ would set product {product_id} to draft")
            archived += 1
            continue

        try:
            archive_product(session, rest_base, product_id, args.throttle)
            archived += 1
            print(f"  âœ… Archived product id {product_id}")
        except Exception as exc:  # pylint: disable=broad-except
            print(f"  âŒ Failed to archive product id {product_id}: {exc}")
            skipped += 1

    print("\nSummary")
    print(f"  â€¢ Handles processed: {len(archive_handles)}")
    print(f"  â€¢ Products archived: {archived}")
    print(f"  â€¢ Products skipped:  {skipped}")
    if missing_handles:
        print(f"  â€¢ Missing handles:   {', '.join(missing_handles[:10])}{'â€¦' if len(missing_handles) > 10 else ''}")
    if args.dry_run:
        print("  â€¢ Mode: dry-run (no changes applied)")

    return 0


if __name__ == "__main__":
    raise SystemExit(main())
